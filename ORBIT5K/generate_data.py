import sys
sys.path.append("../")
import torch
from torch.distributions import Bernoulli
from sklearn.model_selection import train_test_split
import os
from utils.preprocess import noise, dtm_transform


def gen_orbit(num_pts, rho):
    """Generate one orbit.

    Args:
        num_pts (int): Number of points in one orbit.
        rho (float): Parameter defining the dynamical system.

    Returns:
        X (tensor of shape (num_pts, 2)): A 2D orbit (point cloud) in [0,1] x [0,1].
    """
    X = torch.zeros(num_pts, 2)
    x, y = torch.rand(1).item(), torch.rand(1).item()
    for i in range(num_pts):
        x = (x + rho * y * (1-y)) % 1
        y = (y + rho * x * (1-x)) % 1
        X[i] = torch.tensor([x, y])
    return X


def gen_orbits(rhos=[2.5, 3.5, 4.0, 4.1, 4.3], num_pts=1000, num_orbits_each=1000):
    """Generate entire ORBIT dataset.

    Args:
        rhos (list, optional): List of parameters defining the dynamical system. Defaults to [2.5, 3.5, 4.0, 4.1, 4.3].
        num_pts (int, optional): Number of points in one orbit. Defaults to 1000.
        num_orbits_each (int, optional): Number of samples for each label. Defaults to 1000.

    Returns:
        _type_: _description_
    """
    X = torch.zeros(len(rhos)*num_orbits_each, num_pts, 2)
    y = []
    for label, rho in enumerate(rhos):
        for i in range(num_orbits_each):
            X[label*num_orbits_each + i] = gen_orbit(num_pts, rho)
            y.append(label)
    return X, torch.tensor(y)


def pc2grid(X, by=0.025):
    """Map point clouds onto a grid.

    Args:
        X (tensor of of shape (B, num_pts, 2)): Batch of 2D point clouds.
        by (float, optional): Interval between each grid point. Defaults to 0.025.

    Returns:
        X_grid (tensor of shape (B, 1, grid_size, grid_size)): Batch of 2D images generated by mapping points clouds onto a grid.
    """
    grid_size = int(1./by)  # size of one side of square grid
    X_grid = torch.zeros(X.shape[0], grid_size, grid_size)
    for i in range(len(X)):
        orbit_int = torch.floor(X[i] / by).to(int) - (X[i] == 1.).to(int)
        for iPt in range(len(orbit_int)):
            X_grid[i][orbit_int[iPt][0], grid_size-1-orbit_int[iPt][1]] += 1
    X_grid = 2 * torch.sigmoid(X_grid) - 1
    return X_grid.unsqueeze(1)


def gen_noise_data(noise_prob, rhos=[2.5, 3.5, 4.0, 4.1, 4.3], num_pts=1000, num_orbits_each=1000, val_size=0.3, test_size=0.3):
    """Generate ORBIT data that are contaminated by noise.

    Args:
        noise_prob (list): List containing corruption and noise probabilities.
        rhos (list, optional): List of parameters defining the dynamical system. Defaults to [2.5, 3.5, 4.0, 4.1, 4.3].
        num_pts (int, optional): Number of points in one orbit. Defaults to 1000.
        num_orbits_each (int, optional): Number of data for each label. Defaults to 1000.
        val_size (float, optional): Proportion of validation split (after splitting test data). Defaults to 0.3.
        test_size (float, optional): Proportion of test split. Defaults to 0.3.
    """

    X, y = gen_orbits(rhos, num_pts, num_orbits_each=num_orbits_each)
    # split test data
    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, shuffle=True, stratify=y)
    # split val data
    x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=val_size, random_state=42, shuffle=True, stratify=y_train)
    
    for p in noise_prob:
        # contaminate data
        X_tr_noise = noise(x_tr, p)
        X_val_noise = noise(x_val, p)
        X_test_noise = noise(x_test, p)

        # align point cloud to grid
        X_tr_grid = pc2grid(X_tr_noise, by=0.025)
        X_val_grid = pc2grid(X_val_noise, by=0.025)
        X_test_grid = pc2grid(X_test_noise, by=0.025)

        # apply DTM
        X_tr_dtm = dtm_transform(X_tr_noise, m0=0.02, lims=[[0.0125, 0.9875], [0.0125, 0.9875]], size=[40, 40], weighted=False)
        X_val_dtm = dtm_transform(X_val_noise, m0=0.02, lims=[[0.0125, 0.9875], [0.0125, 0.9875]], size=[40, 40], weighted=False)
        X_test_dtm = dtm_transform(X_test_noise, m0=0.02, lims=[[0.0125, 0.9875], [0.0125, 0.9875]], size=[40, 40], weighted=False)

        dir = "./dataset/" + str(int(p * 100)).zfill(2) + "/"
        os.makedirs(dir)
        torch.save((X_tr_grid, X_tr_dtm, y_tr), f=dir + f"train.pt")
        torch.save((X_val_grid, X_val_dtm, y_val), f=dir + f"val.pt")
        torch.save((X_test_grid, X_test_dtm, y_test), f=dir + f"test.pt")


if __name__ == "__main__":
    noise_prob = [0.0, 0.05, 0.1, 0.15, 0.2]    # noise probabilities
    rhos=[2.5, 3.5, 4.0, 4.1, 4.3]              # parameters defining the dynamical system
    num_pts=1000                                # number of points in one orbit
    num_orbits_each = 500                       # number of samples for each label
    val_size=0.3                                # proportion of validation split (after splitting test data)
    test_size=0.3                               # proportion of test split

    torch.manual_seed(42)
    gen_noise_data(noise_prob, rhos, num_pts, num_orbits_each, val_size, test_size)